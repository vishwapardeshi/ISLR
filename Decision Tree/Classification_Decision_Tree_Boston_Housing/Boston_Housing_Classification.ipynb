{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "IMT575 PS1.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "qcz7XRSsBdOd",
        "ilOy6kj8C2NM",
        "_VC8YfirmHY4",
        "004Nx5ejmWy1",
        "n0lTLFKCmgRf"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UrwqYFXVBcDz",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "<h1>Classification of Boston Houses using Decision Trees</h1>\n",
        "\n",
        "---\n",
        "This problem set has 4 parts: \n",
        "\n",
        "\n",
        "1.   <a href='#Part1'>Creating Helper Functions</a>\n",
        "2.   <a href='#Part2'>Building Trees</a>\n",
        "3.   <a href='#Part3'>Making Predictions</a>\n",
        "4.   <a href='#Part4'>Comparing to out-of-the-box classifiers</a>\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O_fWN6S4-XVC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#import libraries\n",
        "import math #for entropy calculation\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from random import choices\n",
        "\n",
        "from sklearn import tree # for decision tree\n",
        "from sklearn.datasets import load_boston #for loading dataset\n",
        "from sklearn.metrics import accuracy_score \n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "import graphviz #for visualization of tree\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qcz7XRSsBdOd",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "---\n",
        "\n",
        "<a id='Part1'></a>\n",
        "# Section 1: Creating Helper Functions \n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-BLbsFhgTShF",
        "colab_type": "text"
      },
      "source": [
        "Creating three helper functions to calculate:\n",
        "\n",
        "\n",
        "1.   Gini Impurity\n",
        "2.   Entropy\n",
        "3.   Weighted Sum\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KLVOcNh1Sc6p",
        "colab_type": "text"
      },
      "source": [
        "#### 1. **calcGini:** Helper function to calculate Gini impurity\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ck2bWBU3loq0",
        "colab_type": "text"
      },
      "source": [
        "> *Input parameters:* Count of each class (assume only two classes for this problem set)\n",
        "\n",
        "> *Output:* Gini Impurity\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CycgCyabU8_K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def calcGini(count_A, count_B):\n",
        "  prob_A = count_A / (count_A + count_B)\n",
        "  prob_B = 1 - prob_A\n",
        "\n",
        "  #calculate gini impurity \n",
        "  gini = 1 - prob_A ** 2 - prob_B ** 2\n",
        "  return gini"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UkM3pagkU8eO",
        "colab_type": "text"
      },
      "source": [
        "#### 2. **calcEntropy**: Helper function to calculate Entropy\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IrvzzSjMlr-H",
        "colab_type": "text"
      },
      "source": [
        "> Input parameters: Count of each class (assume only two classes for this problem set)\n",
        "\n",
        "> Output: Entropy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L6LoOt5x_-h6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def calcEntropy(count_A, count_B):\n",
        "  prob_A = count_A / (count_A + count_B)\n",
        "  prob_B = 1 - prob_A\n",
        "\n",
        "  #calculate entropy \n",
        "  try:\n",
        "    entropy = - (prob_A * math.log (prob_A, 2) + prob_B * math.log (prob_B, 2))\n",
        "  except (ValueError):\n",
        "    entropy = 0\n",
        "  return entropy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SpVftEvAALzy",
        "colab_type": "text"
      },
      "source": [
        "#### 3. **weightedSum:** Helper function to calculate Gini impurity\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yhczkjYslyKh",
        "colab_type": "text"
      },
      "source": [
        "> Input parameters: List of values and counts\n",
        "\n",
        "> Output: Weighted Sum of values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iYeHr0qjAAfq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def weightedSum(values, weights):\n",
        "  \n",
        "  weighted_sum = 0\n",
        "  for i in range(len(values)):\n",
        "    weighted_sum += values[i] * weights[i]\n",
        "  return weighted_sum"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k_xJt3UlBLT6",
        "colab_type": "text"
      },
      "source": [
        "#### 4. Verify that your functions are working as expected\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cn7bvG0s-1bi",
        "colab_type": "text"
      },
      "source": [
        "We first import the toyData into a pandas Dataframe"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "clikvYeUtefe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 352
        },
        "outputId": "da81fd76-5674-4503-b0a3-1fd252029ccd"
      },
      "source": [
        "#importing toy data set \n",
        "toy_data = pd.read_csv(\"toyData.csv\")\n",
        "toy_data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Variable A</th>\n",
              "      <th>Variable B</th>\n",
              "      <th>Variable C</th>\n",
              "      <th>Output</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Yes</td>\n",
              "      <td>On</td>\n",
              "      <td>High</td>\n",
              "      <td>Red</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>No</td>\n",
              "      <td>Off</td>\n",
              "      <td>Low</td>\n",
              "      <td>Blue</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Yes</td>\n",
              "      <td>On</td>\n",
              "      <td>High</td>\n",
              "      <td>Red</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Yes</td>\n",
              "      <td>Off</td>\n",
              "      <td>High</td>\n",
              "      <td>Red</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>No</td>\n",
              "      <td>On</td>\n",
              "      <td>High</td>\n",
              "      <td>Blue</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Yes</td>\n",
              "      <td>On</td>\n",
              "      <td>Low</td>\n",
              "      <td>Blue</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>No</td>\n",
              "      <td>Off</td>\n",
              "      <td>High</td>\n",
              "      <td>Blue</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>No</td>\n",
              "      <td>On</td>\n",
              "      <td>High</td>\n",
              "      <td>Blue</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Yes</td>\n",
              "      <td>On</td>\n",
              "      <td>Low</td>\n",
              "      <td>Blue</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Yes</td>\n",
              "      <td>Off</td>\n",
              "      <td>High</td>\n",
              "      <td>Red</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  Variable A Variable B Variable C Output\n",
              "0        Yes         On       High    Red\n",
              "1         No        Off        Low   Blue\n",
              "2        Yes         On       High    Red\n",
              "3        Yes        Off       High    Red\n",
              "4         No         On       High   Blue\n",
              "5        Yes         On        Low   Blue\n",
              "6         No        Off       High   Blue\n",
              "7         No         On       High   Blue\n",
              "8        Yes         On        Low   Blue\n",
              "9        Yes        Off       High    Red"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zAvlKHpWKTXl",
        "colab_type": "text"
      },
      "source": [
        "As can be observed all the columns have two unique values, thus our helper functions which were built with the assumption of binary class can be used for each of the column."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bh7rbbrAfXF_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#get subset \n",
        "def subset(df, col, val):\n",
        "  return df.loc[df[col] == val]\n",
        "\n",
        "def getColumnCount(df, col, col_unique):\n",
        "  count_1, count_2 = 0, 0\n",
        "  k = 0\n",
        "  for i in col_unique:\n",
        "    if i in set(df[col]):\n",
        "      count = (df[col] == i).sum()\n",
        "      if k == 0:\n",
        "        count_1 = count\n",
        "      elif k == 1:\n",
        "        count_2 = count\n",
        "    k += 1\n",
        "  return count_1, count_2\n",
        "      \n",
        "#get count of target within a particular coolumn\n",
        "#use subset of dataframe\n",
        "def getGiniTotal(df, col, col_unique, target, target_unique):\n",
        "  #get count of columns\n",
        "\n",
        "  count_1, count_2 = getColumnCount(df, col, col_unique)\n",
        "  gini_col = []\n",
        "  prob_1 = count_1 / (count_1 + count_2)\n",
        "  weight = [prob_1, 1 - prob_1] \n",
        "  for v in col_unique:\n",
        "    #get subset of the df\n",
        "    sub_df = subset(df, col, v)\n",
        "    count_a, count_b = getColumnCount(sub_df, target, target_unique)\n",
        "    gini_col.append(round(calcGini(count_a, count_b), 6))\n",
        "  gini = round(weightedSum(gini_col, weight),6)\n",
        "  return gini_col, gini\n",
        "\n",
        "def getEntropyTotal(df, col, col_unique, target, target_unique):\n",
        "  #get count of columns\n",
        "  #get unique columns \n",
        "  \n",
        "  count_1, count_2 = getColumnCount(df, col, col_unique)\n",
        "  entropy_col = []\n",
        "  prob_1 = count_1 / (count_1 + count_2)\n",
        "  weight = [prob_1, 1 - prob_1] \n",
        "  for v in col_unique:\n",
        "    #get subset of the df\n",
        "    sub_df = subset(df, col, v)\n",
        "    count_a, count_b = getColumnCount(sub_df, target, target_unique)\n",
        "    entropy_col.append(round(calcEntropy(count_a, count_b), 6))\n",
        "  entropy = round(weightedSum(entropy_col, weight),6)\n",
        "  return entropy_col, entropy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4xC1GwDb-rmW",
        "colab_type": "text"
      },
      "source": [
        "To find gini impurity of each column in toyData"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nLkfko0gQ0W5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 263
        },
        "outputId": "f1c0f2b5-8260-4e61-88c9-92e549dc62a9"
      },
      "source": [
        "#find gini impurity for all columns\n",
        "for col in toy_data.columns[:3]:\n",
        "  target = \"Output\"\n",
        "  var_col = toy_data[col].unique()\n",
        "  var_target = toy_data[target].unique()\n",
        "  gini_col, gini = getGiniTotal(toy_data, col, var_col, target, var_target)\n",
        "  print(\"\\nFor \", col, \":\\nColumn Value\\t\", var_col[0], \"\\t\", var_col[1], \"\\nGini Impurity\\t%.2f\" % gini_col[0], \"\\t%.2f\"% gini_col[1], \"\\nTotal Gini Impurity: \", round(gini, 2))\n",
        " "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "For  Variable A :\n",
            "Column Value\t Yes \t No \n",
            "Gini Impurity\t0.44 \t0.00 \n",
            "Total Gini Impurity:  0.27\n",
            "\n",
            "For  Variable B :\n",
            "Column Value\t On \t Off \n",
            "Gini Impurity\t0.44 \t0.50 \n",
            "Total Gini Impurity:  0.47\n",
            "\n",
            "For  Variable C :\n",
            "Column Value\t High \t Low \n",
            "Gini Impurity\t0.49 \t0.00 \n",
            "Total Gini Impurity:  0.34\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SxNhLJIWzZ30",
        "colab_type": "text"
      },
      "source": [
        "To now find the entropy of each column in toyData\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UCl3uWMSpo7q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 263
        },
        "outputId": "3c36034b-0a61-4076-9f5f-0ffec2943526"
      },
      "source": [
        "for col in toy_data.columns[:3]:\n",
        "  target = \"Output\"\n",
        "  var_col = toy_data[col].unique()\n",
        "  var_target = toy_data[target].unique()\n",
        "  entropy_col, entropy = getEntropyTotal(toy_data, col, var_col, target, var_target)\n",
        "  print(\"\\nFor \", col, \":\\nColumn Value\\t\", var_col[0], \"\\t\", var_col[1], \"\\nEntropy\\t\\t%.2f\" % entropy_col[0], \"\\t%.2f\"% entropy_col[1], \"\\nTotal Entropy: \", round(entropy,2))\n",
        " "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "For  Variable A :\n",
            "Column Value\t Yes \t No \n",
            "Entropy\t\t0.92 \t0.00 \n",
            "Total Entropy:  0.55\n",
            "\n",
            "For  Variable B :\n",
            "Column Value\t On \t Off \n",
            "Entropy\t\t0.92 \t1.00 \n",
            "Total Entropy:  0.95\n",
            "\n",
            "For  Variable C :\n",
            "Column Value\t High \t Low \n",
            "Entropy\t\t0.99 \t0.00 \n",
            "Total Entropy:  0.69\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dhRuu456_V0j",
        "colab_type": "text"
      },
      "source": [
        "As can be cross-checked, the toyData entropy and gini impurity value is same as that calculated in lecture."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DzYEvnNUERud",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "---\n",
        "\n",
        "<a id='Part2'></a>\n",
        "# Section 2: Building Trees\n",
        "\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ilOy6kj8C2NM",
        "colab_type": "text"
      },
      "source": [
        "#### 5. Import the Boston using dataset using sklearn.datasets\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jvLv5Gk8wBBr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "boston = load_boston()\n",
        "\n",
        "#convert to dataframe\n",
        "boston_df = pd.DataFrame(boston.data)\n",
        "boston_df.columns = boston.feature_names\n",
        "boston_df['MEDV'] = pd.Series(boston.target)\n",
        "\n",
        "#create a new response variable using MEDV > 35K\n",
        "boston_df['highPriced'] = [True if value > 35.0 else False for value in boston_df['MEDV']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uGheUdkQTV6W",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "91b5ce88-53bb-407f-e87d-89c56f19fe32"
      },
      "source": [
        "boston_df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>CRIM</th>\n",
              "      <th>ZN</th>\n",
              "      <th>INDUS</th>\n",
              "      <th>CHAS</th>\n",
              "      <th>NOX</th>\n",
              "      <th>RM</th>\n",
              "      <th>AGE</th>\n",
              "      <th>DIS</th>\n",
              "      <th>RAD</th>\n",
              "      <th>TAX</th>\n",
              "      <th>PTRATIO</th>\n",
              "      <th>B</th>\n",
              "      <th>LSTAT</th>\n",
              "      <th>MEDV</th>\n",
              "      <th>highPriced</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.00632</td>\n",
              "      <td>18.0</td>\n",
              "      <td>2.31</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.538</td>\n",
              "      <td>6.575</td>\n",
              "      <td>65.2</td>\n",
              "      <td>4.0900</td>\n",
              "      <td>1.0</td>\n",
              "      <td>296.0</td>\n",
              "      <td>15.3</td>\n",
              "      <td>396.90</td>\n",
              "      <td>4.98</td>\n",
              "      <td>24.0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.02731</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.07</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.469</td>\n",
              "      <td>6.421</td>\n",
              "      <td>78.9</td>\n",
              "      <td>4.9671</td>\n",
              "      <td>2.0</td>\n",
              "      <td>242.0</td>\n",
              "      <td>17.8</td>\n",
              "      <td>396.90</td>\n",
              "      <td>9.14</td>\n",
              "      <td>21.6</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.02729</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.07</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.469</td>\n",
              "      <td>7.185</td>\n",
              "      <td>61.1</td>\n",
              "      <td>4.9671</td>\n",
              "      <td>2.0</td>\n",
              "      <td>242.0</td>\n",
              "      <td>17.8</td>\n",
              "      <td>392.83</td>\n",
              "      <td>4.03</td>\n",
              "      <td>34.7</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.03237</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.18</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.458</td>\n",
              "      <td>6.998</td>\n",
              "      <td>45.8</td>\n",
              "      <td>6.0622</td>\n",
              "      <td>3.0</td>\n",
              "      <td>222.0</td>\n",
              "      <td>18.7</td>\n",
              "      <td>394.63</td>\n",
              "      <td>2.94</td>\n",
              "      <td>33.4</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.06905</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.18</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.458</td>\n",
              "      <td>7.147</td>\n",
              "      <td>54.2</td>\n",
              "      <td>6.0622</td>\n",
              "      <td>3.0</td>\n",
              "      <td>222.0</td>\n",
              "      <td>18.7</td>\n",
              "      <td>396.90</td>\n",
              "      <td>5.33</td>\n",
              "      <td>36.2</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      CRIM    ZN  INDUS  CHAS    NOX  ...  PTRATIO       B  LSTAT  MEDV  highPriced\n",
              "0  0.00632  18.0   2.31   0.0  0.538  ...     15.3  396.90   4.98  24.0       False\n",
              "1  0.02731   0.0   7.07   0.0  0.469  ...     17.8  396.90   9.14  21.6       False\n",
              "2  0.02729   0.0   7.07   0.0  0.469  ...     17.8  392.83   4.03  34.7       False\n",
              "3  0.03237   0.0   2.18   0.0  0.458  ...     18.7  394.63   2.94  33.4       False\n",
              "4  0.06905   0.0   2.18   0.0  0.458  ...     18.7  396.90   5.33  36.2        True\n",
              "\n",
              "[5 rows x 15 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gHPK4rOiBjZt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "fa5fde60-9367-4b04-f3e5-38b7e35ade63"
      },
      "source": [
        "plt.hist(boston_df.MEDV)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([ 21.,  55.,  82., 154.,  84.,  41.,  30.,   8.,  10.,  21.]),\n",
              " array([ 5. ,  9.5, 14. , 18.5, 23. , 27.5, 32. , 36.5, 41. , 45.5, 50. ]),\n",
              " <a list of 10 Patch objects>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ql6zIl3gXBMo",
        "colab_type": "text"
      },
      "source": [
        "As can be observed from the histogram of MEDV, we observe that before 35k the median price of households are fairly normally distributed and only after that does it deviate. Thus, I believe that the split at 35k captures high priced or not adequately. Additionally, as one would expect the highPriced homes should constitute a lesser number compared to well or low priced. This is reflected in the count below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9WL5fuQVAs9P",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "82578ccb-d744-4fa9-d59a-29716e892fcc"
      },
      "source": [
        "boston_df.highPriced.value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False    458\n",
              "True      48\n",
              "Name: highPriced, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_VC8YfirmHY4",
        "colab_type": "text"
      },
      "source": [
        "#### 6. Using your helper functions & with highPriced as your output, find what the best split is along the AGE variable using each of Gini impurity and entropy as the splitting criterion\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CdvRo-PnMaE9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#function to get the axis-aligned splits between every pair of data points\n",
        "def getMean(df, col):\n",
        "  sort_col = sorted(df[col].unique())\n",
        "  mean = []\n",
        "  for i in range(len(sort_col) - 1):\n",
        "    mean.append(round(((sort_col[i] + sort_col[i+1])/2), 3))\n",
        "  return mean"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-zt_lOGUzcqO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#to find the optimal split based on either entropy or gini impurity\n",
        "def getBestSplit(df, col, target):\n",
        "  var_col = [0,1]\n",
        "  var_target = [False, True]\n",
        "  bool_df = pd.DataFrame()\n",
        "  bool_df[target] = pd.Series(df[target])\n",
        "  minGini = 2\n",
        "  minEntropy = 2\n",
        "  mean = getMean(df, col)\n",
        "  g_split, e_split = mean[0], mean[0]\n",
        "  for m in mean:\n",
        "    bool_df[col] = [1 if value >= m else 0 for value in df[col]]\n",
        "    bool_df.head()\n",
        "    _, currentgini = getGiniTotal(bool_df, col, var_col, target, var_target)\n",
        "    _, currentEntropy = getEntropyTotal(bool_df, col, var_col, target, var_target)\n",
        "    if currentgini < minGini:\n",
        "      minGini = currentgini\n",
        "      g_split = m\n",
        "    if currentEntropy < minEntropy:\n",
        "      minEntropy = currentEntropy\n",
        "      e_split = m\n",
        "  print(\"The optimal split for \", col, \" based on\\n\",minEntropy, \" entropy is @ split \", \\\n",
        "        e_split, \"\\n\",minGini, \" Gini Impurity is @ split\",   g_split)\n",
        "  return e_split, minEntropy, g_split, minGini\n",
        " "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XeaUQ5qYAftS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 151
        },
        "outputId": "36dcd7bf-3651-4373-94d8-1f6a59c90cd1"
      },
      "source": [
        "#for age \n",
        "getBestSplit(boston_df.loc[:, [\"AGE\", \"highPriced\"]], \"AGE\", \"highPriced\")\n",
        "#for crim\n",
        "getBestSplit(boston_df.loc[:, [\"CRIM\", \"highPriced\"]], \"CRIM\", \"highPriced\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The optimal split for  AGE  based on\n",
            " 0.446827  entropy is @ split  37.25 \n",
            " 0.170228  Gini Impurity is @ split 37.25\n",
            "The optimal split for  CRIM  based on\n",
            " 0.432977  entropy is @ split  9.281 \n",
            " 0.168571  Gini Impurity is @ split 0.022\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(9.281, 0.432977, 0.022, 0.168571)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hUs8sFpeFJ73",
        "colab_type": "text"
      },
      "source": [
        "The optimal split for AGE remains the same i.e. 37.25 for both gini impurity and entropy. However, this is not the case for CRIM where the split points are widely different depending on the impurity factor. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "004Nx5ejmWy1",
        "colab_type": "text"
      },
      "source": [
        "#### 7. Import sklearn's DecisionTreeClassifier & find what the optimal split is along the AGE variable using entropy\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8c9pi5BubZ3v",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 135
        },
        "outputId": "fae4cce3-d3c6-4ba1-86e7-724e12dff0c6"
      },
      "source": [
        "#select x - predictor ; y -target\n",
        "x = pd.DataFrame(boston_df.loc[:, [\"AGE\"]])\n",
        "y = pd.DataFrame(boston_df.loc[:, 'highPriced'])\n",
        "\n",
        "#fit tree using x and y and limit depth to 1 and using entropy as an impurity factor\n",
        "age_model = tree.DecisionTreeClassifier(max_depth = 1, criterion= 'entropy')\n",
        "age_model.fit(x, y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='entropy',\n",
              "                       max_depth=1, max_features=None, max_leaf_nodes=None,\n",
              "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                       min_samples_leaf=1, min_samples_split=2,\n",
              "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
              "                       random_state=None, splitter='best')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NKlpMQuhdz-T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#function to display tree\n",
        "def display_tree(dot_file):\n",
        "  with open(dot_file) as f:\n",
        "    dot_graph = f.read()\n",
        "  return graphviz.Source(dot_graph)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EmwhnqkGnpet",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 260
        },
        "outputId": "f397ed82-fcb8-4a54-a164-f16c85783164"
      },
      "source": [
        "tree.export_graphviz(age_model, out_file='age.dot', feature_names=x.columns)\n",
        "display_tree(\"age.dot\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<graphviz.files.Source at 0x7f5acc4d9780>"
            ],
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n -->\n<!-- Title: Tree Pages: 1 -->\n<svg width=\"254pt\" height=\"165pt\"\n viewBox=\"0.00 0.00 253.50 165.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 161)\">\n<title>Tree</title>\n<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-161 249.5,-161 249.5,4 -4,4\"/>\n<!-- 0 -->\n<g id=\"node1\" class=\"node\">\n<title>0</title>\n<polygon fill=\"none\" stroke=\"#000000\" points=\"179.5,-157 62.5,-157 62.5,-89 179.5,-89 179.5,-157\"/>\n<text text-anchor=\"middle\" x=\"121\" y=\"-141.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">AGE &lt;= 37.25</text>\n<text text-anchor=\"middle\" x=\"121\" y=\"-126.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">entropy = 0.452</text>\n<text text-anchor=\"middle\" x=\"121\" y=\"-111.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">samples = 506</text>\n<text text-anchor=\"middle\" x=\"121\" y=\"-96.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">value = [458, 48]</text>\n</g>\n<!-- 1 -->\n<g id=\"node2\" class=\"node\">\n<title>1</title>\n<polygon fill=\"none\" stroke=\"#000000\" points=\"110,-53 0,-53 0,0 110,0 110,-53\"/>\n<text text-anchor=\"middle\" x=\"55\" y=\"-37.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">entropy = 0.61</text>\n<text text-anchor=\"middle\" x=\"55\" y=\"-22.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">samples = 100</text>\n<text text-anchor=\"middle\" x=\"55\" y=\"-7.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">value = [85, 15]</text>\n</g>\n<!-- 0&#45;&gt;1 -->\n<g id=\"edge1\" class=\"edge\">\n<title>0&#45;&gt;1</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M97.7309,-88.9777C91.656,-80.0954 85.0979,-70.5067 78.9865,-61.5711\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"81.8286,-59.5267 73.2943,-53.2485 76.0507,-63.4785 81.8286,-59.5267\"/>\n<text text-anchor=\"middle\" x=\"68.6825\" y=\"-74.1194\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">True</text>\n</g>\n<!-- 2 -->\n<g id=\"node3\" class=\"node\">\n<title>2</title>\n<polygon fill=\"none\" stroke=\"#000000\" points=\"245.5,-53 128.5,-53 128.5,0 245.5,0 245.5,-53\"/>\n<text text-anchor=\"middle\" x=\"187\" y=\"-37.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">entropy = 0.407</text>\n<text text-anchor=\"middle\" x=\"187\" y=\"-22.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">samples = 406</text>\n<text text-anchor=\"middle\" x=\"187\" y=\"-7.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">value = [373, 33]</text>\n</g>\n<!-- 0&#45;&gt;2 -->\n<g id=\"edge2\" class=\"edge\">\n<title>0&#45;&gt;2</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M144.2691,-88.9777C150.344,-80.0954 156.9021,-70.5067 163.0135,-61.5711\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"165.9493,-63.4785 168.7057,-53.2485 160.1714,-59.5267 165.9493,-63.4785\"/>\n<text text-anchor=\"middle\" x=\"173.3175\" y=\"-74.1194\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">False</text>\n</g>\n</g>\n</svg>\n"
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UiZ2Yd0BFrQ_",
        "colab_type": "text"
      },
      "source": [
        "The optimal split value for AGE variable given by sklearn's DecisionTreeClassifier is the same as the one calculated in Q. 6 by using the helper functions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n0lTLFKCmgRf",
        "colab_type": "text"
      },
      "source": [
        "#### 8. Using the RM, LSTAT, and RAD variables, build a decision tree with 2 levels ( 3 split points, 4 leaf nodes) based on entropy.\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q5LiM2r-wXYc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#create subset of database containing RM, LSTAT, RAD, highPriced\n",
        "scratch_df = boston_df.loc[:, ['RM', 'LSTAT', \"RAD\", \"highPriced\"]]\n",
        "\n",
        "#create an empmty dataframe with columns - level, col, threshold to store the tree\n",
        "scratch_tree = pd.DataFrame(columns = ['level', 'col', 'threshold'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yrKiDAyyxk5S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#function to find the column with lowest entropy and its split/threshold\n",
        "def bestSplitLevel(columns, threshold, entropy):\n",
        "  i = entropy.index(min(entropy))\n",
        "  return( columns[i], threshold[i])\n",
        "\n",
        "#to find split for a node\n",
        "def getSplit(df,columns, custom_tree, level):\n",
        "  e_values = []\n",
        "  e_threshold = []\n",
        "  for col in columns:\n",
        "    e_split, entropy, _, _ = getBestSplit(df, col, \"highPriced\")\n",
        "    e_values.append(entropy)\n",
        "    e_threshold.append(e_split)\n",
        "  #find bestSplit for node\n",
        "  column, threshold = bestSplitLevel(columns, e_threshold, e_values)\n",
        "  rows = pd.DataFrame([[level, column, threshold]], columns=['level','col','threshold'])\n",
        "  custom_tree = pd.concat([custom_tree, rows], ignore_index= True)\n",
        "  return custom_tree"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E9nk35v4M4Tj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def twoLevelTree(df, columns, tree):\n",
        "  #first split \n",
        "  tree = getSplit(df, columns, tree, 1)\n",
        "  #subset data based on level 1 split\n",
        "  left_df = df.loc[df[tree.loc[0, 'col']] < tree.loc[0, 'threshold']]\n",
        "  right_df =  df.loc[df[tree.loc[0, 'col']] >= tree.loc[0, 'threshold']]\n",
        "  tree = getSplit(left_df, columns, tree, 2)\n",
        "  tree = getSplit(right_df, columns, tree, 2)\n",
        "  return tree"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uTYOoHsznhdl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 461
        },
        "outputId": "89a617ac-f2ed-4739-c6e9-90acb513bfc2"
      },
      "source": [
        "scratch_tree = twoLevelTree(scratch_df, ['RM', \"LSTAT\", \"RAD\"], scratch_tree)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The optimal split for  RM  based on\n",
            " 0.239064  entropy is @ split  6.941 \n",
            " 0.075922  Gini Impurity is @ split 7.437\n",
            "The optimal split for  LSTAT  based on\n",
            " 0.288778  entropy is @ split  5.155 \n",
            " 0.111971  Gini Impurity is @ split 5.155\n",
            "The optimal split for  RAD  based on\n",
            " 0.441105  entropy is @ split  16.0 \n",
            " 0.169434  Gini Impurity is @ split 16.0\n",
            "The optimal split for  RM  based on\n",
            " 0.101172  entropy is @ split  6.68 \n",
            " 0.027228  Gini Impurity is @ split 6.68\n",
            "The optimal split for  LSTAT  based on\n",
            " 0.082353  entropy is @ split  9.535 \n",
            " 0.024631  Gini Impurity is @ split 3.745\n",
            "The optimal split for  RAD  based on\n",
            " 0.099819  entropy is @ split  16.0 \n",
            " 0.027251  Gini Impurity is @ split 16.0\n",
            "The optimal split for  RM  based on\n",
            " 0.603137  entropy is @ split  7.437 \n",
            " 0.270862  Gini Impurity is @ split 7.437\n",
            "The optimal split for  LSTAT  based on\n",
            " 0.809759  entropy is @ split  5.185 \n",
            " 0.374207  Gini Impurity is @ split 5.185\n",
            "The optimal split for  RAD  based on\n",
            " 0.939004  entropy is @ split  16.0 \n",
            " 0.46039  Gini Impurity is @ split 16.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vGrENJoxnudY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "outputId": "2339d7f3-10b5-44d9-86e4-a556e75dff03"
      },
      "source": [
        "scratch_tree.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>level</th>\n",
              "      <th>col</th>\n",
              "      <th>threshold</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>RM</td>\n",
              "      <td>6.941</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>LSTAT</td>\n",
              "      <td>9.535</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>RM</td>\n",
              "      <td>7.437</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  level    col  threshold\n",
              "0     1     RM      6.941\n",
              "1     2  LSTAT      9.535\n",
              "2     2     RM      7.437"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GZVREDL5qndN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        },
        "outputId": "47053301-1f6a-48f7-c1e2-8552ff160411"
      },
      "source": [
        "#check for decision tree using sklearn\n",
        "#use decisionTreeClassifier to find optimal split \n",
        "scratch_model = tree.DecisionTreeClassifier(max_depth = 2, criterion= 'entropy')\n",
        "scratch_model.fit(scratch_df.loc[:, ['RM', \"LSTAT\", \"RAD\"]], (scratch_df.loc[:, \"highPriced\"]))\n",
        "tree.export_graphviz(scratch_model, out_file='custom1.dot', feature_names= (scratch_df.loc[:, ['RM', \"LSTAT\", \"RAD\"]]).columns)\n",
        "display_tree(\"custom1.dot\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<graphviz.files.Source at 0x7f5acc4ca550>"
            ],
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n -->\n<!-- Title: Tree Pages: 1 -->\n<svg width=\"504pt\" height=\"269pt\"\n viewBox=\"0.00 0.00 504.00 269.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 265)\">\n<title>Tree</title>\n<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-265 500,-265 500,4 -4,4\"/>\n<!-- 0 -->\n<g id=\"node1\" class=\"node\">\n<title>0</title>\n<polygon fill=\"none\" stroke=\"#000000\" points=\"306.5,-261 189.5,-261 189.5,-193 306.5,-193 306.5,-261\"/>\n<text text-anchor=\"middle\" x=\"248\" y=\"-245.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">RM &lt;= 6.941</text>\n<text text-anchor=\"middle\" x=\"248\" y=\"-230.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">entropy = 0.452</text>\n<text text-anchor=\"middle\" x=\"248\" y=\"-215.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">samples = 506</text>\n<text text-anchor=\"middle\" x=\"248\" y=\"-200.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">value = [458, 48]</text>\n</g>\n<!-- 1 -->\n<g id=\"node2\" class=\"node\">\n<title>1</title>\n<polygon fill=\"none\" stroke=\"#000000\" points=\"241,-157 123,-157 123,-89 241,-89 241,-157\"/>\n<text text-anchor=\"middle\" x=\"182\" y=\"-141.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">LSTAT &lt;= 9.535</text>\n<text text-anchor=\"middle\" x=\"182\" y=\"-126.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">entropy = 0.106</text>\n<text text-anchor=\"middle\" x=\"182\" y=\"-111.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">samples = 430</text>\n<text text-anchor=\"middle\" x=\"182\" y=\"-96.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">value = [424, 6]</text>\n</g>\n<!-- 0&#45;&gt;1 -->\n<g id=\"edge1\" class=\"edge\">\n<title>0&#45;&gt;1</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M226.3891,-192.9465C220.8622,-184.2373 214.8494,-174.7626 209.0854,-165.6801\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"211.9729,-163.6979 203.6594,-157.13 206.0626,-167.4487 211.9729,-163.6979\"/>\n<text text-anchor=\"middle\" x=\"198.2058\" y=\"-177.8279\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">True</text>\n</g>\n<!-- 4 -->\n<g id=\"node5\" class=\"node\">\n<title>4</title>\n<polygon fill=\"none\" stroke=\"#000000\" points=\"369,-157 259,-157 259,-89 369,-89 369,-157\"/>\n<text text-anchor=\"middle\" x=\"314\" y=\"-141.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">RM &lt;= 7.437</text>\n<text text-anchor=\"middle\" x=\"314\" y=\"-126.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">entropy = 0.992</text>\n<text text-anchor=\"middle\" x=\"314\" y=\"-111.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">samples = 76</text>\n<text text-anchor=\"middle\" x=\"314\" y=\"-96.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">value = [34, 42]</text>\n</g>\n<!-- 0&#45;&gt;4 -->\n<g id=\"edge4\" class=\"edge\">\n<title>0&#45;&gt;4</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M269.6109,-192.9465C275.1378,-184.2373 281.1506,-174.7626 286.9146,-165.6801\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"289.9374,-167.4487 292.3406,-157.13 284.0271,-163.6979 289.9374,-167.4487\"/>\n<text text-anchor=\"middle\" x=\"297.7942\" y=\"-177.8279\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">False</text>\n</g>\n<!-- 2 -->\n<g id=\"node3\" class=\"node\">\n<title>2</title>\n<polygon fill=\"none\" stroke=\"#000000\" points=\"110,-53 0,-53 0,0 110,0 110,-53\"/>\n<text text-anchor=\"middle\" x=\"55\" y=\"-37.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">entropy = 0.262</text>\n<text text-anchor=\"middle\" x=\"55\" y=\"-22.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">samples = 135</text>\n<text text-anchor=\"middle\" x=\"55\" y=\"-7.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">value = [129, 6]</text>\n</g>\n<!-- 1&#45;&gt;2 -->\n<g id=\"edge2\" class=\"edge\">\n<title>1&#45;&gt;2</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M137.2246,-88.9777C124.5708,-79.3629 110.8277,-68.9203 98.2647,-59.3743\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"100.2824,-56.5118 90.2027,-53.2485 96.0474,-62.0853 100.2824,-56.5118\"/>\n</g>\n<!-- 3 -->\n<g id=\"node4\" class=\"node\">\n<title>3</title>\n<polygon fill=\"none\" stroke=\"#000000\" points=\"238,-53 128,-53 128,0 238,0 238,-53\"/>\n<text text-anchor=\"middle\" x=\"183\" y=\"-37.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">entropy = 0.0</text>\n<text text-anchor=\"middle\" x=\"183\" y=\"-22.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">samples = 295</text>\n<text text-anchor=\"middle\" x=\"183\" y=\"-7.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">value = [295, 0]</text>\n</g>\n<!-- 1&#45;&gt;3 -->\n<g id=\"edge3\" class=\"edge\">\n<title>1&#45;&gt;3</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M182.3526,-88.9777C182.438,-80.7364 182.5297,-71.887 182.6164,-63.5153\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"186.1189,-63.2842 182.7228,-53.2485 179.1193,-63.2116 186.1189,-63.2842\"/>\n</g>\n<!-- 5 -->\n<g id=\"node6\" class=\"node\">\n<title>5</title>\n<polygon fill=\"none\" stroke=\"#000000\" points=\"368,-53 258,-53 258,0 368,0 368,-53\"/>\n<text text-anchor=\"middle\" x=\"313\" y=\"-37.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">entropy = 0.859</text>\n<text text-anchor=\"middle\" x=\"313\" y=\"-22.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">samples = 46</text>\n<text text-anchor=\"middle\" x=\"313\" y=\"-7.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">value = [33, 13]</text>\n</g>\n<!-- 4&#45;&gt;5 -->\n<g id=\"edge5\" class=\"edge\">\n<title>4&#45;&gt;5</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M313.6474,-88.9777C313.562,-80.7364 313.4703,-71.887 313.3836,-63.5153\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"316.8807,-63.2116 313.2772,-53.2485 309.8811,-63.2842 316.8807,-63.2116\"/>\n</g>\n<!-- 6 -->\n<g id=\"node7\" class=\"node\">\n<title>6</title>\n<polygon fill=\"none\" stroke=\"#000000\" points=\"496,-53 386,-53 386,0 496,0 496,-53\"/>\n<text text-anchor=\"middle\" x=\"441\" y=\"-37.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">entropy = 0.211</text>\n<text text-anchor=\"middle\" x=\"441\" y=\"-22.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">samples = 30</text>\n<text text-anchor=\"middle\" x=\"441\" y=\"-7.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">value = [1, 29]</text>\n</g>\n<!-- 4&#45;&gt;6 -->\n<g id=\"edge6\" class=\"edge\">\n<title>4&#45;&gt;6</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M358.7754,-88.9777C371.4292,-79.3629 385.1723,-68.9203 397.7353,-59.3743\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"399.9526,-62.0853 405.7973,-53.2485 395.7176,-56.5118 399.9526,-62.0853\"/>\n</g>\n</g>\n</svg>\n"
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n9jE1RkHMnlB",
        "colab_type": "text"
      },
      "source": [
        "The decision tree built using the custome function is shown in the table above. The decision tree depicted above was built using the sklearn's DecisionTreeClassifier package. \n",
        "\n",
        "It can be observed that the splits identified by the custom functions are exactly at the same place as those produced by the sklearn's package. This was a sanity check performed. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HDAGY9xxmrNV",
        "colab_type": "text"
      },
      "source": [
        "#### 9. Visualize your splits on an X-Y plane\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bYBzQ-P1NnJt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 294
        },
        "outputId": "73784f4a-f7ee-4aec-a989-6053e7ccdb95"
      },
      "source": [
        "classes = ['False', 'True']\n",
        "scatter = plt.scatter(boston_df.RM, boston_df.LSTAT,c = boston_df.highPriced)\n",
        "plt.title(\"Data Split\")\n",
        "plt.legend(handles=scatter.legend_elements()[0], labels=classes)\n",
        "plt.axvline(x=6.941)\n",
        "plt.axvline(x=7.437)\n",
        "plt.axhline(y=9.535, xmax = 0.63)\n",
        "plt.xlabel('RM')\n",
        "plt.ylabel('LSTAT')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uU11gsM2WC4l",
        "colab_type": "text"
      },
      "source": [
        "The lines here represent the split as were identified using the helper function for the above tree. The vertical split are for RM and horizontal for values of LSTAT. This divides the X-Y plane into 4 parts as is expected as there are four leaf nodes which are produced. \n",
        "\n",
        "As can be observed from the visualization above, the top left rectangle has only False values whereas the extreme right rectangle has only True values. The remaining two rectangles have a mix of False and True values for highPriced columns."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NhLAl9nPEZyr",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "---\n",
        "\n",
        "<a id='Part3'></a>\n",
        "# Section 3: Making Predictions\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L-hK8gYBnHVe",
        "colab_type": "text"
      },
      "source": [
        "#### 10. Create a training/test split for your data\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gpdYZAuCnQli",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 65
        },
        "outputId": "d1992d82-020b-424f-96ba-719ef1eb56ab"
      },
      "source": [
        "#filter by 5 \n",
        "test_df = boston_df[boston_df.index % 5 == 0]\n",
        "train_df = boston_df.append(test_df).drop_duplicates(keep=False)\n",
        "row_train = train_df.shape[0]\n",
        "row_test = test_df.shape[0]\n",
        "print(\"The number of observations in:\\nTrain Dataset: \", row_train , \"\\nTest Dataset: \", row_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The number of observations in:\n",
            "Train Dataset:  404 \n",
            "Test Dataset:  102\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "azUFmlCSieKm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#x - feature labels - RM, LSTAT, \n",
        "x_train = pd.DataFrame(train_df.loc[:, ['RM', 'LSTAT']])\n",
        "x_test = pd.DataFrame(test_df.loc[:, ['RM', 'LSTAT']])\n",
        "\n",
        "#y - target label\n",
        "y_train = pd.DataFrame(train_df.loc[:, 'highPriced'])\n",
        "y_test = pd.DataFrame(test_df.loc[:, 'highPriced'])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nWAfyA3Bj3Qz",
        "colab_type": "text"
      },
      "source": [
        "Target variable - highPriced distribution using histogram.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V9w3foRAlZYO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "outputId": "bdcc2d22-10f1-4f95-f182-1818e4966282"
      },
      "source": [
        "Y = [train_df.iloc[:, -1].tolist(), test_df.iloc[:, -1].tolist()]\n",
        "df = pd.DataFrame(list(zip(*Y)), columns=['Train', 'Test'])\n",
        "df.apply(pd.value_counts).plot.bar()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f5acbe1e400>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAEICAYAAACktLTqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAARBklEQVR4nO3dfZBddXnA8e+T3WRXSUogLBizaoIiCgUS3AGBmQpGRh1QMlO1ONAJlRkGq2BLGd4sNX2hA31DM7U4URCcYRQLMoHitFVKJjAgdIMMBAMl5XVpAutWQtACCTz94x5wDRuyu/fePdnf/X5mMnvPuffsfTKT/ebsueeeG5mJJKksM+oeQJLUesZdkgpk3CWpQMZdkgpk3CWpQMZdkgrUXfcAAPvss08uXLiw7jEkaVpZt27dzzOzb6z7dou4L1y4kMHBwbrHkKRpJSKe2Nl9HpaRpAIZd0kq0C7jHhFXRcSzEbF+1Lq9I+JHEfFI9XWvan1ExMqI2BgR90fE4e0cXpI0tvEcc78a+EfgO6PWXQDcmpmXRsQF1fL5wMeBA6o/RwJXVF8lqaW2bdvG0NAQL774Yt2jtF1vby/9/f3MnDlz3NvsMu6ZuTYiFu6w+iTg2Or2NcAaGnE/CfhONq5G9pOImBsR8zNz07gnkqRxGBoaYs6cOSxcuJCIqHuctslMRkZGGBoaYtGiRePebrLH3PcbFezNwH7V7QXAU6MeN1Stk6SWevHFF5k3b17RYQeICObNmzfh31CafkG12kuf8HWDI+KMiBiMiMHh4eFmx5DUgUoP+2sm8/ecbNyfiYj51ZPOB56t1j8NvGPU4/qrdW+QmasycyAzB/r6xjwHX5J2WyMjIyxevJjFixfztre9jQULFry+/PLLL7/ptoODg5x99tltnW+yb2K6CVgOXFp9XT1q/Rcj4ns0XkjdUtLx9oUX3FL3COPy+KUn1D2CNOVa/fO5q5+jefPmcd999wGwYsUKZs+ezbnnnvv6/du3b6e7e+zEDgwMMDAw0LphxzCeUyG/C9wFHBgRQxFxOo2oHx8RjwAfqZYBfgg8CmwEvgn8YVumlqTd0GmnncaZZ57JkUceyXnnncc999zDUUcdxZIlSzj66KN5+OGHAVizZg0nnngi0PiP4XOf+xzHHnss+++/PytXrmzJLOM5W+azO7lr6RiPTeALzQ4lSdPV0NAQd955J11dXTz//PPcfvvtdHd38+Mf/5iLLrqIG2644Q3bPPTQQ9x2221s3bqVAw88kM9//vMTOu1xLLvFtWUkqRSf/vSn6erqAmDLli0sX76cRx55hIhg27ZtY25zwgkn0NPTQ09PD/vuuy/PPPMM/f39Tc3h5QckqYX22GOP129ffPHFHHfccaxfv56bb755p6cz9vT0vH67q6uL7du3Nz2HcZekNtmyZQsLFjTe6nP11VdP6XMbd0lqk/POO48LL7yQJUuWtGRvfCKi8RpovQYGBnI6XM/dUyGl3ceGDRt4//vfX/cYU2asv29ErMvMMc+pdM9dkgrk2TIlWrFn3ROMz4otdU8gFcs9d0kqkHGXpAIZd0kqkHGXpAL5gqokTcLIyAhLlzYusbV582a6urp47fLl99xzD7NmzXrT7desWcOsWbM4+uij2zKfcZdUhlafJbaLs7l2dcnfXVmzZg2zZ89uW9w9LCNJLbJu3To+9KEP8YEPfICPfvSjbNrU+DiLlStXctBBB3HooYdy8skn8/jjj/ONb3yDyy+/nMWLF3P77be3fBb33CWpBTKTs846i9WrV9PX18d1113Hl7/8Za666iouvfRSHnvsMXp6enjuueeYO3cuZ5555oT39ifCuEtSC7z00kusX7+e448/HoBXXnmF+fPnA3DooYdyyimnsGzZMpYtWzYl8xh3SWqBzOTggw/mrrvuesN9t9xyC2vXruXmm2/mkksu4YEHHmj7PB5zl6QW6OnpYXh4+PW4b9u2jQcffJBXX32Vp556iuOOO47LLruMLVu28MILLzBnzhy2bt3atnmMuyS1wIwZM7j++us5//zzOeyww1i8eDF33nknr7zyCqeeeiqHHHIIS5Ys4eyzz2bu3Ll84hOf4MYbb/QFVUl6UzVeiG7FihWv3167du0b7r/jjjvesO69730v999/f9tmcs9dkgpk3CWpQMZdkgpk3CVNW7vDx4ROhcn8PY27pGmpt7eXkZGR4gOfmYyMjNDb2zuh7TxbRtK01N/fz9DQEMPDw3WP0na9vb309/dPaBvjLmlamjlzJosWLap7jN2Wh2UkqUDGXZIKZNwlqUDGXZIKZNwlqUDGXZIK1FTcI+KPI+LBiFgfEd+NiN6IWBQRd0fExoi4LiLe/CPAJUktN+m4R8QC4GxgIDN/G+gCTgYuAy7PzPcAvwBOb8WgkqTxa/awTDfwlojoBt4KbAI+DFxf3X8NMDUfGChJet2k456ZTwN/BzxJI+pbgHXAc5m5vXrYELCg2SElSRPTzGGZvYCTgEXA24E9gI9NYPszImIwIgY74doQkjSVmjks8xHgscwczsxtwA+AY4C51WEagH7g6bE2zsxVmTmQmQN9fX1NjCFJ2lEzcX8S+GBEvDUiAlgK/Ay4DfhU9ZjlwOrmRpQkTVQzx9zvpvHC6b3AA9X3WgWcD5wTERuBecCVLZhTkjQBTV3yNzO/Anxlh9WPAkc0830lSc3xHaqSVCDjLkkFMu6SVCDjLkkFMu6SVCDjLkkFMu6SVCDjLkkFMu6SVCDjLkkFMu6SVCDjLkkFMu6SVCDjLkkFMu6SVCDjLkkFMu6SVCDjLkkFMu6SVCDjLkkFMu6SVCDjLkkFMu6SVCDjLkkFMu6SVCDjLkkFMu6SVCDjLkkFMu6SVCDjLkkFMu6SVCDjLkkFMu6SVKCm4h4RcyPi+oh4KCI2RMRREbF3RPwoIh6pvu7VqmElSePT7J7714B/zcz3AYcBG4ALgFsz8wDg1mpZkjSFJh33iNgT+B3gSoDMfDkznwNOAq6pHnYNsKzZISVJE9PMnvsiYBj4dkT8NCK+FRF7APtl5qbqMZuB/ZodUpI0Mc3EvRs4HLgiM5cAv2SHQzCZmUCOtXFEnBERgxExODw83MQYkqQdNRP3IWAoM++ulq+nEftnImI+QPX12bE2zsxVmTmQmQN9fX1NjCFJ2tGk456Zm4GnIuLAatVS4GfATcDyat1yYHVTE0qSJqy7ye3PAq6NiFnAo8Af0PgP4/sRcTrwBPCZJp9DkjRBTcU9M+8DBsa4a2kz31eS1BzfoSpJBTLuklQg4y5JBTLuklQg4y5JBTLuklQg4y5JBTLuklQg4y5JBTLuklQg4y5JBTLuklQg4y5JBTLuklQg4y5JBTLuklQg4y5JBTLuklQg4y5JBTLuklQg4y5JBTLuklQg4y5JBTLuklQg4y5JBTLuklQg4y5JBTLuklQg4y5JBTLuklQg4y5JBTLuklQg4y5JBWo67hHRFRE/jYh/qZYXRcTdEbExIq6LiFnNjylJmohW7Ll/Cdgwavky4PLMfA/wC+D0FjyHJGkCmop7RPQDJwDfqpYD+DBwffWQa4BlzTyHJGnimt1z/ypwHvBqtTwPeC4zt1fLQ8CCJp9DkjRBk457RJwIPJuZ6ya5/RkRMRgRg8PDw5MdQ5I0hmb23I8BPhkRjwPfo3E45mvA3Ijorh7TDzw91saZuSozBzJzoK+vr4kxJEk7mnTcM/PCzOzPzIXAycB/ZOYpwG3Ap6qHLQdWNz2lJGlC2nGe+/nAORGxkcYx+Cvb8BySpDfRveuH7FpmrgHWVLcfBY5oxfeVJE2O71CVpAIZd0kqkHGXpAIZd0kqkHGXpAIZd0kqkHGXpAIZd0kqkHGXpAIZd0kqkHGXpAIZd0kqkHGXpAIZd0kqkHGXpAIZd0kqkHGXpAIZd0kqkHGXpAIZd0kqkHGXpAIZd0kqkHGXpAIZd0kqkHGXpAIZd0kqkHGXpAIZd0kqkHGXpAIZd0kqkHGXpAIZd0kqkHGXpAJNOu4R8Y6IuC0ifhYRD0bEl6r1e0fEjyLikerrXq0bV5I0Hs3suW8H/iQzDwI+CHwhIg4CLgBuzcwDgFurZUnSFJp03DNzU2beW93eCmwAFgAnAddUD7sGWNbskJKkiWnJMfeIWAgsAe4G9svMTdVdm4H9WvEckqTxazruETEbuAH4o8x8fvR9mZlA7mS7MyJiMCIGh4eHmx1DkjRKU3GPiJk0wn5tZv6gWv1MRMyv7p8PPDvWtpm5KjMHMnOgr6+vmTEkSTto5myZAK4ENmTmP4y66yZgeXV7ObB68uNJkiaju4ltjwF+H3ggIu6r1l0EXAp8PyJOB54APtPciJKkiZp03DPzDiB2cvfSyX5fSVLzfIeqJBXIuEtSgYy7JBXIuEtSgYy7JBXIuEtSgYy7JBXIuEtSgYy7JBXIuEtSgYy7JBXIuEtSgYy7JBXIuEtSgYy7JBXIuEtSgYy7JBXIuEtSgYy7JBXIuEtSgYy7JBXIuEtSgbrrHkBSB1mxZ90TjM+KLXVP0DT33CWpQMZdkgpk3CWpQMZdkgpk3CWpQMZdkgpk3CWpQJ7nLhVg4QW31D3CuDzeW/cEncM9d0kqkHGXpAK1Je4R8bGIeDgiNkbEBe14DknSzrU87hHRBXwd+DhwEPDZiDio1c8jSdq5duy5HwFszMxHM/Nl4HvASW14HknSTrQj7guAp0YtD1XrJElTpLZTISPiDOCMavGFiHi4rllKE7AP8PO659ilP4+6J9AU899my71rZ3e0I+5PA+8YtdxfrfsNmbkKWNWG5+94ETGYmQN1zyHtyH+bU6cdh2X+EzggIhZFxCzgZOCmNjyPJGknWr7nnpnbI+KLwL8BXcBVmflgq59HkrRzbTnmnpk/BH7Yju+tcfFwl3ZX/tucIpGZdc8gSWoxLz8gSQUy7pJUIOMuqW2i4dSI+LNq+Z0RcUTdc3UC416IiHhrRFwcEd+slg+IiBPrnksd75+Ao4DPVstbaVx7Sm1m3MvxbeAlGj9I0Hjj2F/VN44EwJGZ+QXgRYDM/AUwq96ROoNxL8e7M/NvgG0AmfkrYNq8h1rF2lZdKTYBIqIPeLXekTqDcS/HyxHxFn79Q/RuGnvyUp1WAjcC+0bEJcAdwF/XO1Jn8Dz3QkTE8cCf0riG/r8DxwCnZeaaOueSIuJ9wFIav0nempkbah6pIxj3gkTEPOCDNH6IfpKZu//V91S0iHjnWOsz88mpnqXTGPdCRMQxwH2Z+cuIOBU4HPhaZj5R82jqYBHxAI1DhQH0AouAhzPz4FoH6wAecy/HFcCvIuIw4Bzgv4Hv1DuSOl1mHpKZh1ZfD6DxSW131T1XJzDu5diejV/DTgK+nplfB+bUPJP0GzLzXuDIuufoBLV9EpNabmtEXAicCvxORMwAZtY8kzpcRJwzanEGjcOF/1PTOB3FPfdy/B6NUx9Pz8zNND4B62/rHUlizqg/PcAtNH67VJv5gqqktqjevHRZZp5b9yydyMMy01xEbKV649KOdwGZmb81xSNJRER39alsx9Q9S6dyz11Sy0XEvZl5eERcASwA/hn45Wv3Z+YPahuuQ7jnXpiI2JfG+cSAbxZR7XqBEeDD/Pp89wSMe5sZ90JExCeBvwfeDjwLvAvYAPhmEdVh3+pMmfX8Ouqv8XDBFPBsmXL8JY1LD/xXZi6icS2Pn9Q7kjpYFzC7+jNn1O3X/qjN3HMvx7bMHImIGRExIzNvi4iv1j2UOtamzPyLuofoZMa9HM9FxGxgLXBtRDzLqBewpCnmZwnUzLNlprmIeGdmPhkRewD/R+NQ2ynAnsC1mTlS64DqSBGxd2b+b91zdDLjPs29dspZdfuGzPzdumeSVD9fUJ3+Rv/6u39tU0jarRj36S93cltSB/OwzDQXEa/QeOE0gLcAv3rtLrz8gNSxjLskFcjDMpJUIOMuSQUy7pJUIOMuSQUy7pJUoP8HCJMk3gNELwkAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OZfZWu1nVKIt",
        "colab_type": "text"
      },
      "source": [
        "The target variable - highPriced has almost the same distribution of values in both training and test dataset as observed from the histogram."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ydJsXM6XnLb9",
        "colab_type": "text"
      },
      "source": [
        "#### 11. Create a baseline set of predictions\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YLbGSR2w6ZL6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#get predictions by sampling 404 training rows with replacement to get test predictions for 102 rows\n",
        "baseline = choices(y_train['highPriced'].values.tolist(), k = row_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Alay_sQ68EOb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 32
        },
        "outputId": "41813e25-aee8-48ef-bedc-a3916b9dc28d"
      },
      "source": [
        "base_accuracy = accuracy_score(y_test, baseline)\n",
        "print('Baseline prediction accuracy: {:.2f}'.format(base_accuracy)) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Baseline prediction accuracy: 0.87\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KjN9aR1aV6xH",
        "colab_type": "text"
      },
      "source": [
        "The baseline prediction gives an accuracy of 87% this might be attributed to the resampling method which was employed."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CGbNGvVqnONe",
        "colab_type": "text"
      },
      "source": [
        "#### 12. Now, use a 2-level decision tree to make predictions\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EiD5CbKCrI7p",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "outputId": "bb5773d7-9102-4927-d8c3-17009e1bd6f9"
      },
      "source": [
        "#create an empmty dataframe with columns - level, col, threshold to store the tree\n",
        "train_tree = pd.DataFrame(columns = ['level', 'col', 'threshold'])\n",
        "train_tree = twoLevelTree(train_df.loc[:, [\"RM\", \"LSTAT\", 'highPriced']], ['RM', \"LSTAT\"], train_tree)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The optimal split for  RM  based on\n",
            " 0.251054  entropy is @ split  7.127 \n",
            " 0.080615  Gini Impurity is @ split 7.437\n",
            "The optimal split for  LSTAT  based on\n",
            " 0.307043  entropy is @ split  5.155 \n",
            " 0.116821  Gini Impurity is @ split 4.265\n",
            "The optimal split for  RM  based on\n",
            " 0.150378  entropy is @ split  6.678 \n",
            " 0.046732  Gini Impurity is @ split 6.941\n",
            "The optimal split for  LSTAT  based on\n",
            " 0.126534  entropy is @ split  5.115 \n",
            " 0.042679  Gini Impurity is @ split 5.115\n",
            "The optimal split for  RM  based on\n",
            " 0.539052  entropy is @ split  7.437 \n",
            " 0.239632  Gini Impurity is @ split 7.437\n",
            "The optimal split for  LSTAT  based on\n",
            " 0.586375  entropy is @ split  3.99 \n",
            " 0.293076  Gini Impurity is @ split 3.99\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Hj6gSeRZIlj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "outputId": "18dbc523-9879-4ab0-be53-63f1954ecdb4"
      },
      "source": [
        "train_tree.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>level</th>\n",
              "      <th>col</th>\n",
              "      <th>threshold</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>RM</td>\n",
              "      <td>7.127</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>LSTAT</td>\n",
              "      <td>5.115</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>RM</td>\n",
              "      <td>7.437</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  level    col  threshold\n",
              "0     1     RM      7.127\n",
              "1     2  LSTAT      5.115\n",
              "2     2     RM      7.437"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xhv0BG2xeLIt",
        "colab_type": "text"
      },
      "source": [
        "The above dataframe shows the two-level tree created using predictors - RM, LSTAT which was trained on the training data. The function below predicts value for test dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sG_vcIxqcID1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import random\n",
        "#make predictions\n",
        "def predict(train_df, test_df):\n",
        "  node_1, node_2, node_3, node_4 = [], [], [], []\n",
        "  for _, r in train_df.iterrows():\n",
        "    #find samples belonging to nodes \n",
        "    if r.RM < 7.127:\n",
        "      if r.LSTAT < 5.115:\n",
        "        node_1.append(r.highPriced)\n",
        "      else:\n",
        "        node_2.append(r.highPriced)\n",
        "    else:\n",
        "      if r.RM < 7.437:\n",
        "        node_3.append(r.highPriced)\n",
        "      else:\n",
        "        node_4.append(r.highPriced)\n",
        "      \n",
        "  predict = []\n",
        "  for _, r in test_df.iterrows():\n",
        "    #sample to predict\n",
        "    if r.RM < 7.127:\n",
        "      if r.LSTAT < 5.115:\n",
        "        predict.append(random.choice(node_1))\n",
        "      else:\n",
        "        predict.append(random.choice(node_2))\n",
        "    else:\n",
        "      if r.RM < 7.437:\n",
        "        predict.append(random.choice(node_3))\n",
        "      else:\n",
        "        predict.append(random.choice(node_4))\n",
        "  return predict"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ym9LYslQZOH0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 32
        },
        "outputId": "0ee790eb-bae7-4115-d696-c83be4683b9d"
      },
      "source": [
        "predict_y = predict(train_df, test_df)\n",
        "tree_accuracy = accuracy_score(y_test, predict_y)\n",
        "print('Test set accuracy for tree trained on training data using helper functions: {:.2f}'.format(tree_accuracy)) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test set accuracy for tree trained on training data using helper functions: 0.93\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yD_tb60udhJ6",
        "colab_type": "text"
      },
      "source": [
        "The accuracy of this tree generated using the helper function is 93%. This is higher compared to the baseline prediction's accuracy of 87%. This tree is also different than the one which was trained using the whole dataset as will be expected. While the split nodes remain the same in terms of columns, the value is different. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IBR041q5EfyH",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "<a id='Part4'></a>\n",
        "# Section 4: Comparing to out-of-the-box classifiers\n",
        "\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ta5EDeHQndkV",
        "colab_type": "text"
      },
      "source": [
        "#### 13. Use sklearn’s DecisionTreeClassifier to recreate the decision tree that is trained on the training data.\n",
        "\n",
        "\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_3Bt6P2Qqpej",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 115
        },
        "outputId": "6e4e3f0c-d19e-4247-e948-4c5c53d69c9e"
      },
      "source": [
        "model_1 = tree.DecisionTreeClassifier(max_depth = 2, criterion='entropy')\n",
        "model_1.fit(x_train, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='entropy',\n",
              "                       max_depth=2, max_features=None, max_leaf_nodes=None,\n",
              "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                       min_samples_leaf=1, min_samples_split=2,\n",
              "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
              "                       random_state=None, splitter='best')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ls4BcNHOphhY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        },
        "outputId": "f4495d6b-f193-44c5-d44d-8ed88d2b618d"
      },
      "source": [
        "tree.export_graphviz(model_1, out_file='tree_1.dot', feature_names=x_train.columns)\n",
        "display_tree(\"tree_1.dot\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<graphviz.files.Source at 0x7f5acc4c5b38>"
            ],
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n -->\n<!-- Title: Tree Pages: 1 -->\n<svg width=\"504pt\" height=\"269pt\"\n viewBox=\"0.00 0.00 504.00 269.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 265)\">\n<title>Tree</title>\n<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-265 500,-265 500,4 -4,4\"/>\n<!-- 0 -->\n<g id=\"node1\" class=\"node\">\n<title>0</title>\n<polygon fill=\"none\" stroke=\"#000000\" points=\"306.5,-261 189.5,-261 189.5,-193 306.5,-193 306.5,-261\"/>\n<text text-anchor=\"middle\" x=\"248\" y=\"-245.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">RM &lt;= 7.127</text>\n<text text-anchor=\"middle\" x=\"248\" y=\"-230.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">entropy = 0.474</text>\n<text text-anchor=\"middle\" x=\"248\" y=\"-215.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">samples = 404</text>\n<text text-anchor=\"middle\" x=\"248\" y=\"-200.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">value = [363, 41]</text>\n</g>\n<!-- 1 -->\n<g id=\"node2\" class=\"node\">\n<title>1</title>\n<polygon fill=\"none\" stroke=\"#000000\" points=\"240.5,-157 123.5,-157 123.5,-89 240.5,-89 240.5,-157\"/>\n<text text-anchor=\"middle\" x=\"182\" y=\"-141.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">LSTAT &lt;= 5.115</text>\n<text text-anchor=\"middle\" x=\"182\" y=\"-126.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">entropy = 0.169</text>\n<text text-anchor=\"middle\" x=\"182\" y=\"-111.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">samples = 358</text>\n<text text-anchor=\"middle\" x=\"182\" y=\"-96.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">value = [349, 9]</text>\n</g>\n<!-- 0&#45;&gt;1 -->\n<g id=\"edge1\" class=\"edge\">\n<title>0&#45;&gt;1</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M226.3891,-192.9465C220.8622,-184.2373 214.8494,-174.7626 209.0854,-165.6801\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"211.9729,-163.6979 203.6594,-157.13 206.0626,-167.4487 211.9729,-163.6979\"/>\n<text text-anchor=\"middle\" x=\"198.2058\" y=\"-177.8279\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">True</text>\n</g>\n<!-- 4 -->\n<g id=\"node5\" class=\"node\">\n<title>4</title>\n<polygon fill=\"none\" stroke=\"#000000\" points=\"369,-157 259,-157 259,-89 369,-89 369,-157\"/>\n<text text-anchor=\"middle\" x=\"314\" y=\"-141.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">RM &lt;= 7.437</text>\n<text text-anchor=\"middle\" x=\"314\" y=\"-126.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">entropy = 0.887</text>\n<text text-anchor=\"middle\" x=\"314\" y=\"-111.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">samples = 46</text>\n<text text-anchor=\"middle\" x=\"314\" y=\"-96.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">value = [14, 32]</text>\n</g>\n<!-- 0&#45;&gt;4 -->\n<g id=\"edge4\" class=\"edge\">\n<title>0&#45;&gt;4</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M269.6109,-192.9465C275.1378,-184.2373 281.1506,-174.7626 286.9146,-165.6801\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"289.9374,-167.4487 292.3406,-157.13 284.0271,-163.6979 289.9374,-167.4487\"/>\n<text text-anchor=\"middle\" x=\"297.7942\" y=\"-177.8279\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">False</text>\n</g>\n<!-- 2 -->\n<g id=\"node3\" class=\"node\">\n<title>2</title>\n<polygon fill=\"none\" stroke=\"#000000\" points=\"110,-53 0,-53 0,0 110,0 110,-53\"/>\n<text text-anchor=\"middle\" x=\"55\" y=\"-37.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">entropy = 0.764</text>\n<text text-anchor=\"middle\" x=\"55\" y=\"-22.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">samples = 27</text>\n<text text-anchor=\"middle\" x=\"55\" y=\"-7.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">value = [21, 6]</text>\n</g>\n<!-- 1&#45;&gt;2 -->\n<g id=\"edge2\" class=\"edge\">\n<title>1&#45;&gt;2</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M137.2246,-88.9777C124.5708,-79.3629 110.8277,-68.9203 98.2647,-59.3743\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"100.2824,-56.5118 90.2027,-53.2485 96.0474,-62.0853 100.2824,-56.5118\"/>\n</g>\n<!-- 3 -->\n<g id=\"node4\" class=\"node\">\n<title>3</title>\n<polygon fill=\"none\" stroke=\"#000000\" points=\"238,-53 128,-53 128,0 238,0 238,-53\"/>\n<text text-anchor=\"middle\" x=\"183\" y=\"-37.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">entropy = 0.075</text>\n<text text-anchor=\"middle\" x=\"183\" y=\"-22.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">samples = 331</text>\n<text text-anchor=\"middle\" x=\"183\" y=\"-7.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">value = [328, 3]</text>\n</g>\n<!-- 1&#45;&gt;3 -->\n<g id=\"edge3\" class=\"edge\">\n<title>1&#45;&gt;3</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M182.3526,-88.9777C182.438,-80.7364 182.5297,-71.887 182.6164,-63.5153\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"186.1189,-63.2842 182.7228,-53.2485 179.1193,-63.2116 186.1189,-63.2842\"/>\n</g>\n<!-- 5 -->\n<g id=\"node6\" class=\"node\">\n<title>5</title>\n<polygon fill=\"none\" stroke=\"#000000\" points=\"368,-53 258,-53 258,0 368,0 368,-53\"/>\n<text text-anchor=\"middle\" x=\"313\" y=\"-37.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">entropy = 0.934</text>\n<text text-anchor=\"middle\" x=\"313\" y=\"-22.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">samples = 20</text>\n<text text-anchor=\"middle\" x=\"313\" y=\"-7.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">value = [13, 7]</text>\n</g>\n<!-- 4&#45;&gt;5 -->\n<g id=\"edge5\" class=\"edge\">\n<title>4&#45;&gt;5</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M313.6474,-88.9777C313.562,-80.7364 313.4703,-71.887 313.3836,-63.5153\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"316.8807,-63.2116 313.2772,-53.2485 309.8811,-63.2842 316.8807,-63.2116\"/>\n</g>\n<!-- 6 -->\n<g id=\"node7\" class=\"node\">\n<title>6</title>\n<polygon fill=\"none\" stroke=\"#000000\" points=\"496,-53 386,-53 386,0 496,0 496,-53\"/>\n<text text-anchor=\"middle\" x=\"441\" y=\"-37.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">entropy = 0.235</text>\n<text text-anchor=\"middle\" x=\"441\" y=\"-22.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">samples = 26</text>\n<text text-anchor=\"middle\" x=\"441\" y=\"-7.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">value = [1, 25]</text>\n</g>\n<!-- 4&#45;&gt;6 -->\n<g id=\"edge6\" class=\"edge\">\n<title>4&#45;&gt;6</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M358.7754,-88.9777C371.4292,-79.3629 385.1723,-68.9203 397.7353,-59.3743\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"399.9526,-62.0853 405.7973,-53.2485 395.7176,-56.5118 399.9526,-62.0853\"/>\n</g>\n</g>\n</svg>\n"
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "54_-iDMXtce6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 32
        },
        "outputId": "40888184-3b8b-4bc9-c3be-2678dbb0ed0a"
      },
      "source": [
        "y_pred = model_1.predict(x_test)\n",
        "print(\"Test set accuracy for sklearn Decision Tree: {:.4f}\".format(accuracy_score(y_test, y_pred)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test set accuracy for sklearn Decision Tree: 0.9706\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vuM_CgUte12I",
        "colab_type": "text"
      },
      "source": [
        "The decision tree built using sklearn's package gives the same split points as the tree formed in Part 12 by using the custom helper functions. Thus, the splits are at the same location and the probabilities are similiar as in the tree in Part 12.\n",
        "\n",
        "The prediction accuracy for this tree is 97.06% which is higher than both the tree in Part 12 and the baseline predictions which had accuracy of 93% and 88% respectively."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lwZQvy_CniVQ",
        "colab_type": "text"
      },
      "source": [
        "#### 14. Use sklearn’s BaggingClassifier to create a bagging classifier whose base is a DecisionTreeClassifier with 2 levels and entropy as the split criterion.\n",
        "\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "84LQGqeBkrfl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "df921da1-2df7-4a16-f8c5-23bd60aea0b0"
      },
      "source": [
        "dt = tree.DecisionTreeClassifier(criterion = 'entropy', max_depth = 2)\n",
        "bc = BaggingClassifier(base_estimator=dt, n_estimators=100)\n",
        "bc.fit(x_train, y_train)\n",
        "y_pred_bc = bc.predict(x_test)\n",
        "acc_test = accuracy_score(y_test, y_pred_bc)\n",
        "print('Test set accuracy for sklearn Bagged Tree: {:.4f}'.format(acc_test)) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test set accuracy for sklearn Bagged Tree: 0.9706\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/_bagging.py:645: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MWCFD3TEh-Vc",
        "colab_type": "text"
      },
      "source": [
        "The prediction accuracy for bagged decision tree is 97.06% which is higher than both the tree in Part 12 and the baseline predictions which had accuracy of 93% and 88% respectively. However, it has the same accuracy as the basic decision tree of Part 13. It is possible that due to the class imbalance, there isn't a lot of variance to deal with. Thus, there was no marked difference in the accuracy by bagging the decision tree."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HvebCzb9nllv",
        "colab_type": "text"
      },
      "source": [
        "#### 15. Use sklearn’s RandomForestClassifier to create a random forest classifier whose base is a decision tree with 2 levels and entropy as the split criterion.\n",
        "\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P-o4e4vwqtJI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "8e88a97e-dd58-49ee-ada8-969ffcf701da"
      },
      "source": [
        "rf = RandomForestClassifier(n_estimators=100,\n",
        "            random_state=4, criterion = 'entropy', max_depth = 2)\n",
        "rf.fit(x_train, y_train) \n",
        "\n",
        "y_pred_rf = rf.predict(x_test)\n",
        "acc_test_rf = accuracy_score(y_test, y_pred_rf)\n",
        "print('Test set accuracy for sklearn Random Forest: {:.4f}'.format(acc_test_rf)) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test set accuracy for sklearn Random Forest: 0.9706\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OrVcqEfdsXM4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 32
        },
        "outputId": "c8a27a53-49b3-4141-b510-2c357bf100df"
      },
      "source": [
        "# View a list of the features and their importance scores\n",
        "list(zip(x_train, rf.feature_importances_))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('RM', 0.5844199727381939), ('LSTAT', 0.4155800272618062)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QW-avAG4hwH9",
        "colab_type": "text"
      },
      "source": [
        "The prediction accuracy for random forest model is 97.06% which is higher than both the tree in Part 12 and the baseline predictions which had accuracy of 93% and 88% respectively. However, it has the same accuracy as the basic decision tree of Part 13. The features have almost the similar rank of importance as in the trees which were built before this. Once again, RM comes at the top as the most discriminating factor. This was the case with the all the previous trees where the root node split is using RM. "
      ]
    }
  ]
}